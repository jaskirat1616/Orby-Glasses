# OrbyGlasses Configuration File
# Bio-Mimetic Navigation System for Visually Impaired Users

# Camera/Video Source Settings
camera:
  # Source: 0 for built-in webcam, or URL for IP camera (e.g., "http://192.168.1.100:8080/video")
  source: 1
  width: 320  # Smaller size for better performance
  height: 320  # Smaller size for better performance
  fps: 20  # Target FPS

# Model Settings
models:
  # YOLOv12 Object Detection
  yolo:
    path: "models/yolo/yolo12n.pt"
    confidence: 0.65       # High confidence = fewer false positives
    iou_threshold: 0.45    # IoU threshold for NMS
    device: "mps"          # Device: 'mps' (Apple Silicon), 'cuda', or 'cpu'

  # Depth Estimation (Depth Anything V2)
  depth:
    path: "depth-anything/Depth-Anything-V2-Small-hf"  # Hugging Face model name
    device: "mps"

  # LLM for Narrative Generation
  llm:
    primary: "gemma3:4b"        # Primary model for narrative
    vision: "moondream:latest"  # Vision model for scene understanding
    temperature: 0.7            # Sampling temperature (0-1)
    max_tokens: 150             # Maximum tokens to generate

# Conversational Navigation
conversation:
  enabled: true                      # Enable conversational mode
  model: "gemma3:4b"                 # LLM model for conversations
  temperature: 0.7                   # Response creativity (0-1)
  max_tokens: 200                    # Maximum response length
  voice_input: false                  # Enable voice input (requires microphone)
  activation_phrase: "hey orby"      # Wake phrase to start conversation
  check_interval: 1.0                # How often to check for activation (seconds)

# Social Navigation
social_navigation:
  enabled: true                      # Enable social navigation features
  region: "us"                       # Regional social norm ('us', 'uk', 'japan', etc.)
  voice_announce: true               # Announce social navigation advice through voice

# Audio Settings
audio:
  # Text-to-Speech
  tts_engine: "pyttsx3"
  tts_rate: 180              # Words per minute (clear and understandable)
  tts_volume: 0.9            # Volume (0-1)

  # Echolocation/Spatial Audio
  echolocation_enabled: true   # Enabled for audio beaconing
  spatial_audio: false
  
  # Adaptive Audio Beaconing
  adaptive_beaconing_enabled: true  # Enable adaptive audio beaconing (440Hz for safe paths, 880Hz for obstacles)
  beacon_safe_frequency: 440        # Frequency for safe path beacons (Hz)
  beacon_obstacle_frequency: 880    # Frequency for obstacle warnings (Hz)
  warning_pulse_rate: 0.2           # Warning pulse rate in seconds

# Echolocation Simulation Settings
echolocation:
  # Virtual room dimensions [x, y, z] in meters
  room_dimensions: [10, 10, 3]
  sample_rate: 16000         # Audio sample rate in Hz
  duration: 0.1              # Duration of each beep in seconds

# Reinforcement Learning Prediction
prediction:
  enabled: false  # Disabled for better performance - enable after testing
  model_path: "models/rl/ppo_navigation.zip"
  training_steps: 10000      # Steps for initial training
  save_interval: 1000        # Save checkpoint every N steps

# Safety Settings
safety:
  min_safe_distance: 1.5     # Minimum safe distance in meters
  danger_distance: 0.4       # Immediate danger zone (<0.4m) - very close objects only
  caution_distance: 1.5      # Caution zone (0.4-1.5m)
  emergency_stop_key: "q"    # Key to emergency stop
  max_obstacle_alerts: 3     # Maximum simultaneous obstacle alerts

# Logging Settings
logging:
  level: "INFO"              # DEBUG, INFO, WARNING, ERROR, CRITICAL
  log_file: "data/logs/orbyglass.log"
  save_detections: true      # Log detection data for analysis
  save_frames: false         # Save frames (uses lots of space)

# Performance Tuning
performance:
  audio_update_interval: 5.0      # Seconds between audio updates (ensures sentences complete)
  danger_audio_interval: 3.0      # Faster alerts for danger zone objects (increased to reduce spam)
  stats_interval: 100             # Log stats every N frames
  max_detections: 3               # Focus on top 3 most relevant objects
  depth_skip_frames: 3            # Calculate depth every Nth frame (3 = every 4th frame)

# 3D Mapping Settings
mapping3d:
  enabled: false                   # Enable 3D real-time mapping visualization (set to true to enable)
  max_depth: 10.0                 # Maximum depth in meters to visualize
  voxel_size: 0.1                 # Voxel size for downsampling (larger = faster, less detail)
  subsample_step: 8               # Subsample every Nth point (higher = faster, less detail)
  update_interval: 0.3            # Update 3D map every N seconds (slower updates = better performance)
  fx: 500                         # Camera focal length X (pixels)
  fy: 500                         # Camera focal length Y (pixels)
  skip_bbox: true                 # Skip bounding boxes for better performance

# SLAM Settings (Visual Simultaneous Localization and Mapping)
slam:
  enabled: true                   # Enable SLAM for indoor navigation (EXPERIMENTAL)
  grid_size: [200, 200]           # Occupancy grid size (width, height) in cells
  grid_resolution: 0.1            # Grid cell size in meters (0.1m = 10cm per cell)
  save_maps: true                 # Save maps for later reuse
  visualize: true                 # Show SLAM visualization window

# Indoor Navigation Settings
indoor_navigation:
  enabled: true                   # Enable goal-oriented indoor navigation (requires SLAM)
  path_planning: true             # Enable A* path planning
  save_locations: true            # Remember named locations

# Trajectory Prediction Settings (Graph Neural Network)
trajectory_prediction:
  enabled: false                  # Enable GNN-based trajectory prediction (EXPERIMENTAL)
  max_history: 10                 # Number of historical positions to track
  prediction_horizon: 3           # Number of future timesteps to predict
  time_step: 0.5                  # Time between predictions (seconds)
  visualize: false                # Show trajectory visualization
  collision_warning: true         # Warn about predicted collisions
