# ============================================================================
# OrbyGlasses 2025 - Cutting-Edge Dependencies
# Revolutionary AI-Powered Navigation System for Blind Users
# Target: ≥99.5% accuracy, 30+ FPS on edge devices, <50ms latency
# ============================================================================

# Core Python Framework (2025)
python>=3.12
setuptools>=69.0.0
wheel>=0.42.0
poetry>=1.8.0

# Async & Distributed Computing (2025)
asyncio>=3.4.3
aiofiles>=23.2.1
ray[default]>=2.9.0  # Distributed edge inference
uvloop>=0.19.0  # Fast async event loop

# Zenoh - High-performance pub-sub for robotics (NEW)
eclipse-zenoh>=0.11.0  # Much better than threading for real-time systems

# ============================================================================
# PERCEPTION LAYER - Neural AI (2025 SOTA)
# ============================================================================

# Computer Vision Core (2025)
opencv-python>=5.0.0  # Latest OpenCV with neural network optimizations
opencv-contrib-python>=5.0.0  # Extra modules
pillow>=10.2.0
imageio>=2.34.0
scikit-image>=0.22.0

# Object Detection (2025 SOTA)
ultralytics>=8.3.0  # YOLO-World open-vocabulary detection
torch>=2.5.0  # PyTorch 2.5+ with MPS/CUDA optimizations
torchvision>=0.20.0
segment-anything>=2.1.0  # SAM 2.1 for affordance detection
detectron2 @ git+https://github.com/facebookresearch/detectron2.git@main  # Optional

# Depth Estimation (2025 SOTA)
transformers>=4.45.0  # For VLMs and depth models
timm>=1.0.0  # PyTorch Image Models
huggingface_hub>=0.20.0
# Note: depth-anything-v2-plus and patchrefiner will be installed via huggingface hub
# depth-anything-v2-plus>=1.0.0  # Installed via transformers
# patchrefiner>=1.0.0  # Installed via transformers
# metric3d>=2.0.0  # Installed via transformers

# SLAM (2025 Neural Radiance Fields)
open3d>=0.18.0  # 3D data processing
scipy>=1.13.0
# mast3r-slam>=1.0.0  # Will be available soon, placeholder for now
# gaussian-splatting>=1.2.0  # Will be available soon, placeholder for now
pycolmap>=0.6.0  # For bundle adjustment

# ============================================================================
# NAVIGATION LAYER - Deep RL & Path Planning (2025)
# ============================================================================

# Deep Reinforcement Learning (2025)
stable-baselines3>=2.3.0  # PPO for predictive navigation
gymnasium>=0.29.0  # RL environments
tensorboard>=2.16.0  # Training visualization

# Graph Neural Networks (2025)
torch-geometric>=2.5.0  # GNN for social force models
torch-scatter>=2.1.2
torch-sparse>=0.6.18
torch-cluster>=1.6.3

# Path Planning (2025)
networkx>=3.2.1  # Graph algorithms (A*, RRT*)
shapely>=2.0.3  # Geometric operations

# ============================================================================
# COGNITION LAYER - Multimodal LLMs (2025)
# ============================================================================

# Large Language Models (2025)
ollama>=0.3.0  # Local LLM serving
llama-cpp-python>=0.2.85  # Gemma 3 / Llama 3.2-Vision inference
transformers[torch]>=4.45.0  # Hugging Face transformers
accelerate>=0.27.0  # LLM acceleration
bitsandbytes>=0.42.0  # Quantization support

# Speech Recognition (2025)
openai-whisper>=20231117  # Whisper for ASR
# whisper-streaming>=1.0.0  # Real-time ASR (placeholder, use openai-whisper for now)
pyaudio>=0.2.14
SpeechRecognition>=3.10.1

# ============================================================================
# ACTION LAYER - Multi-Modal Feedback (2025)
# ============================================================================

# Audio Synthesis (2025)
pyttsx3>=3.0.0  # Neural TTS
sounddevice>=0.5.0  # Audio playback
soundfile>=0.12.1
librosa>=0.10.1  # Audio processing
pyaudio>=0.2.14
scipy>=1.13.0

# Haptic Feedback (2025)
# hapteq>=2.0.0  # HaptEQ patterns library (placeholder, will be custom)
pyserial>=3.5  # For haptic hardware communication
hidapi>=0.14.0  # HID device support

# Bio-Sensors (2025)
pylsl>=1.16.0  # Lab Streaming Layer for bio-sensors
# polar-h10>=1.0.0  # Polar H10 SDK (placeholder, will use BLE)
# muse-lsl>=2.5.0  # Muse EEG SDK (placeholder, will use LSL)
bleak>=0.21.0  # Bluetooth Low Energy for bio-sensors

# ============================================================================
# EDGE OPTIMIZATION - Quantization & Inference (2025)
# ============================================================================

# Model Optimization (2025)
openvino>=2024.0  # Intel OpenVINO for INT8 quantization
# tensorrt>=10.0.0  # NVIDIA TensorRT (Linux/Windows only)
onnx>=1.16.0
onnxruntime>=1.18.0
onnxruntime-gpu>=1.18.0; platform_system != "Darwin"  # GPU support (non-macOS)
neural-compressor>=2.5.0  # Intel quantization toolkit

# ============================================================================
# BREAKTHROUGH FEATURES - EchoMind, SwarmSense, Neural Companion (2025)
# ============================================================================

# Thermal Vision (EchoMind)
# flir-lepton>=1.0.0  # FLIR Lepton SDK (placeholder, will use custom driver)

# Federated Learning (SwarmSense)
flwr>=1.5.0  # Flower federated learning
cryptography>=42.0.0  # For secure aggregation

# VLC (Visible Light Communication)
# vlc-decoder>=1.0.0  # VLC decoder (placeholder, will be custom)

# ============================================================================
# UTILITIES & INFRASTRUCTURE (2025)
# ============================================================================

# Data Processing
numpy>=1.26.0
pandas>=2.2.0
scipy>=1.13.0

# Configuration & Logging
pyyaml>=6.0.1
colorlog>=6.8.0
rich>=13.7.0  # Beautiful terminal output
loguru>=0.7.2

# Visualization
matplotlib>=3.8.3
seaborn>=0.13.2
plotly>=5.19.0

# Performance Monitoring
psutil>=5.9.8
pynvml>=11.5.0  # NVIDIA GPU monitoring
py-cpuinfo>=9.0.0

# ============================================================================
# TESTING & DEVELOPMENT (2025)
# ============================================================================

# Testing
pytest>=8.2.0
pytest-asyncio>=0.23.0
pytest-cov>=5.0.0
pytest-timeout>=2.2.0
pytest-mock>=3.12.0

# Code Quality
black>=24.2.0
flake8>=7.0.0
mypy>=1.9.0
isort>=5.13.2

# Documentation
sphinx>=7.2.6
sphinx-rtd-theme>=2.0.0
myst-parser>=2.0.0

# ============================================================================
# PLATFORM-SPECIFIC DEPENDENCIES
# ============================================================================

# macOS (Apple Silicon MPS)
coremltools>=8.0; sys_platform == "darwin" and python_version >= "3.11"

# Linux (NVIDIA CUDA)
# nvidia-cudnn>=8.9.0; sys_platform == "linux"
# nvidia-cuda-runtime>=12.0; sys_platform == "linux"

# Raspberry Pi (ARM optimizations)
# armnn>=23.11; platform_machine == "aarch64"

# ============================================================================
# OPTIONAL DEPENDENCIES (Install separately if needed)
# ============================================================================

# [thermal]
# flir-lepton>=1.0.0

# [vlc]
# vlc-decoder>=1.0.0

# [bio-sensors]
# polar-h10>=1.0.0
# muse-lsl>=2.5.0

# [gpu]
# tensorrt>=10.0.0
# onnxruntime-gpu>=1.18.0

# [dev]
# jupyter>=1.0.0
# ipython>=8.22.0
# notebook>=7.1.0

# ============================================================================
# INSTALLATION INSTRUCTIONS
# ============================================================================

# Standard installation:
#   pip install -r requirements_2025.txt

# With Poetry (recommended):
#   poetry install

# With optional dependencies:
#   pip install -r requirements_2025.txt -r requirements_optional.txt

# Edge optimization (Raspberry Pi 5):
#   pip install -r requirements_2025.txt --extra-index-url https://www.piwheels.org/simple

# NVIDIA Jetson:
#   pip install -r requirements_2025.txt --extra-index-url https://pypi.ngc.nvidia.com

# ============================================================================
# NOTES
# ============================================================================

# 1. Some cutting-edge 2025 packages (mast3r-slam, gaussian-splatting) are
#    not yet available on PyPI. They will be installed via git or custom repos.

# 2. For bio-sensors (Polar H10, Muse 2), use Bluetooth Low Energy (bleak)
#    or Lab Streaming Layer (pylsl) for data acquisition.

# 3. For thermal cameras (FLIR Lepton), use custom driver via SPI interface.

# 4. TensorRT is only available on Linux/Windows with NVIDIA GPUs.

# 5. For production deployment, use Docker with pre-built images:
#    - docker pull orbyglass/orbyglass-2025:pi5
#    - docker pull orbyglass/orbyglass-2025:jetson-orin

# ============================================================================
# VERSION COMPATIBILITY
# ============================================================================

# Python: 3.12+
# PyTorch: 2.5.0+ (with MPS support for macOS, CUDA 12.0+ for Linux)
# OpenCV: 5.0.0+ (with DNN module and neural network optimizations)
# Transformers: 4.45.0+ (with Gemma 3 and Llama 3.2-Vision support)
# Ray: 2.9.0+ (with distributed inference and async support)

# ============================================================================
# HARDWARE REQUIREMENTS
# ============================================================================

# Minimum (Raspberry Pi 5):
#   - CPU: ARM Cortex-A76 (4 cores)
#   - RAM: 8GB
#   - Storage: 128GB microSD
#   - Camera: Pi Camera Module 3
#   - Cost: ~$280

# Recommended (NVIDIA Jetson Orin Nano):
#   - GPU: NVIDIA Ampere (1024 CUDA cores)
#   - RAM: 8GB
#   - Storage: 256GB NVMe SSD
#   - Camera: OAK-D Lite (stereo + depth)
#   - Cost: ~$680

# Premium (NVIDIA Jetson Orin NX):
#   - GPU: NVIDIA Ampere (2048 CUDA cores)
#   - RAM: 16GB
#   - Storage: 512GB NVMe SSD
#   - Camera: OAK-D Pro (stereo + depth + IMU)
#   - Thermal: FLIR Lepton 3.5
#   - LiDAR: Slamtec RPLiDAR A1
#   - Bio-sensors: Polar H10 + Muse 2
#   - Cost: ~$1,500

# ============================================================================
# PERFORMANCE TARGETS (2025)
# ============================================================================

# - Detection Accuracy: ≥99.5% mAP (COCO 2025)
# - Depth MAE: <0.15m (NYU Depth V2)
# - SLAM ATE: <0.03m (TUM RGB-D 2025)
# - FPS: 30+ (Raspberry Pi 5), 40+ (Jetson Orin)
# - Latency: <50ms end-to-end
# - Memory: <1GB
# - CPU Usage: <30% (on target hardware)
# - Navigation Success: ≥98% (BLV-sim VR)

# ============================================================================
# LICENSE
# ============================================================================

# MIT License - Open Source
# Copyright (c) 2025 OrbyGlasses Project
