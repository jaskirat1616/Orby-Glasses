# OrbyGlasses - Quick Start Guide

## How to Run OrbyGlasses

### Option 1: Standard Run (Recommended)

```bash
./run.sh
```

This will:
- âœ… Start the camera
- âœ… Load AI models
- âœ… Begin object detection
- âœ… Provide audio guidance
- âœ… Show depth visualization

**Press 'q' to quit**

---

### Option 2: Test Individual Modules

#### Test Depth Estimation
```bash
python3 src/core/depth_anything_v2.py
```
Shows your camera feed with depth colors.

#### Test SLAM Tracking
```bash
python3 src/navigation/simple_slam.py
```
Tracks your position as you move.

#### Test Dark Depth Visualizer
```bash
python3 src/visualization/depth_visualizer_2025.py
```
Shows dark-themed depth map.

---

### Option 3: Run Tests

```bash
# Test all modules
python3 -m pytest tests/ -v

# Test specific module
python3 -m pytest tests/test_depth_visualizer_2025.py -v
```

---

## What You'll See

When running `./run.sh`:

1. **Camera Window**: Shows detected objects with boxes
2. **Depth Map Window**: Shows distance in colors
   - Dark red = Very close (danger!)
   - Orange = Close (caution)
   - Green = Safe distance
   - Blue = Far away
3. **SLAM Map Window**: Shows your position as you move

## What You'll Hear

- **"Navigation system ready"** - System started
- **"Path clear"** - No obstacles ahead
- **"Chair at 2 meters"** - Object detected with distance
- **"Stop! Person ahead. Go left"** - Danger warning with direction

---

## System Requirements

### Already Installed
- âœ… Python 3.11
- âœ… PyTorch
- âœ… OpenCV
- âœ… All core libraries

### Optional (for full features)
```bash
# For YOLO-World text prompts
pip install git+https://github.com/ultralytics/CLIP.git

# For haptic feedback (if you have hardware)
pip install pyserial hidapi
```

---

## Troubleshooting

### "Camera not found"
Make sure your webcam is connected and not being used by another app.

### "No audio"
Check your speaker volume. The system uses macOS 'say' command.

### "Slow performance"
Lower the resolution in `config/config.yaml`:
```yaml
camera:
  width: 320
  height: 240
```

---

## Current Test Results

âœ… **All Core Tests Passing:**
- Depth Visualizer: 11/11 passed
- SLAM Tracking: 4/4 passed
- Depth Estimation: Working
- Haptic Patterns: Working
- Audio Sonification: Working

---

## Features Available Now

### Working Features
- âœ… Real-time object detection (YOLOv11)
- âœ… Depth estimation (Depth Anything V2)
- âœ… Indoor SLAM tracking
- âœ… Dark-themed depth visualization
- âœ… Audio guidance with TTS
- âœ… Haptic pattern generation
- âœ… Audio sonification

### In Development
- â³ YOLO-World (needs CLIP library)
- â³ Bio-adaptive feedback
- â³ VLC beacon navigation

---

## Quick Commands

```bash
# Start system
./run.sh

# Stop system
Press 'q' in the video window

# Run all tests
pytest tests/ -v

# Check status
git status

# Update code
git pull
```

---

## File Structure

```
OrbyGlasses/
â”œâ”€â”€ run.sh                          # Main launcher
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                     # Main application
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ depth_anything_v2.py    # NEW: Better depth
â”‚   â”‚   â”œâ”€â”€ yolo_world_detector.py  # NEW: Open-vocab detection
â”‚   â”‚   â””â”€â”€ detection.py            # Object detection
â”‚   â”œâ”€â”€ navigation/
â”‚   â”‚   â”œâ”€â”€ simple_slam.py          # NEW: Indoor tracking
â”‚   â”‚   â””â”€â”€ slam_system.py          # SLAM
â”‚   â””â”€â”€ visualization/
â”‚       â””â”€â”€ depth_visualizer_2025.py # NEW: Dark theme depth
â”œâ”€â”€ tests/                          # All tests
â””â”€â”€ docs/                           # Documentation
```

---

## Performance

**Current Performance (on your Mac):**
- FPS: ~15-20
- Latency: ~100ms
- Memory: ~2GB
- Detection: Working
- Depth: Working
- SLAM: Working

---

## Getting Help

1. Check `docs/USER_GUIDE_2025.md` for detailed guide
2. Run tests to verify: `pytest tests/ -v`
3. Check GitHub issues: https://github.com/jaskirat1616/Orby-Glasses/issues

---

## Next Steps

1. **Try it now**: `./run.sh`
2. **Walk around**: Watch the SLAM map track your position
3. **Test depth**: Move closer/farther from objects
4. **Listen**: Hear audio guidance as you navigate

**Enjoy your AI-powered navigation system!** ğŸš€
